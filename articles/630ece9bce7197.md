---
title: "KNNã§MNISTã‚’åˆ†é¡(ä»®)"
emoji: "ğŸƒ"
type: "tech"
topics: []
published: false
---

# æ¦‚è¦
ã“ã®è¨˜äº‹ã§ã¯K nearest neighbors(Kè¿‘å‚æ³•)ã‚’ç”¨ã„ã¦MNISTã®åˆ†é¡
* Pythonã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®scikit-learn
ä»Šå›ç”¨ã„ã‚‹ã®ã¯scikit-learnã®ãƒˆã‚¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«æ¨™æº–ã®ç·´ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)

# ã¯ã˜ã‚ã«

## å‰æçŸ¥è­˜

### K nearest neighbors
K nearest neighbors(ä»¥ä¸‹ã€KNNã¨å‘¼ã¶)ã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒå…¥åŠ›ã•ã‚ŒãŸã¨ãã«ãã‚Œã«è¿‘ã„Kå€‹ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šã€ãã‚Œã‚‰ã®ãƒ©ãƒ™ãƒ«ã®å¤šæ•°æ±ºã‚’æ¡ã‚‹ã“ã¨ã§ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒ©ãƒ™ãƒ«ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ã€‚
ç­†è€…ã®ã€[KNN(Kè¿‘å‚æ³•)ã®ä»•çµ„ã¿](https://zenn.dev/kumamoto/articles/bc6230323bc0ad)ã€ã«è©³ã—ã„è§£èª¬ãŒã‚ã‚‹ã€‚

### MNIST
TODO èª­è€…ãŒçŸ¥ã‚ŠãŸã„ã®ã¯ã€MNISTãŒã©ã†ã„ã†DSã‹ã§ã‚ã£ã¦ä½œã‚Šæ–¹ã§ã¯ãªã„ã€ç”»åƒã‚‚è²¼ã£ã¦ãŠã‘
[**MNIST**(Modified National 
Institute of Standards)](http://yann.lecun.com/exdb/mnist/)ã¯0~9ã®æ‰‹æ›¸ãæ•°å­—ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§60,000æšã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨10,000æšã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æœ‰ã—ã¦ã„ã‚‹ã€‚
![](https://storage.googleapis.com/zenn-user-upload/9oucz58gb5wrizfz0ut1ureprpb4)
>MNISTãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«(ä»®)

ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã¯æ—¢ã«(1)28x28ãƒ”ã‚¯ã‚»ãƒ«ã®ç¯„å›²ã«åã¾ã‚‹ã‚ˆã†ã«ã‚µã‚¤ã‚ºãŒæ­£è¦åŒ–ã•ã‚Œã¦ãŠã‚Šã€(2)ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã«ãªã‚‹ã‚ˆã†ã‚¢ãƒ³ãƒã‚¨ã‚¤ãƒªã‚¢ã‚¹å‡¦ç†ã‚‚è¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚
â€»[æ­£è¦åŒ–](https://ja.wikipedia.org/wiki/%E6%AD%A3%E8%A6%8F%E5%8C%96#:~:text=%E6%AD%A3%E8%A6%8F%E5%8C%96%EF%BC%88%E3%81%9B%E3%81%84%E3%81%8D%E3%81%8B%E3%80%81%E8%8B%B1%E8%AA%9E,%E3%81%A6%E3%82%82%E5%90%8C%E7%BE%A9%E3%81%A7%E3%81%82%E3%82%8B%E3%80%82)ã¨ã¯ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€å®šã®ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦å¤‰å½¢ã—åˆ©ç”¨ã—ã‚„ã™ãã™ã‚‹ã“ã¨ã€‚


### äº¤å·®æ¤œè¨¼(Cross Validation)
[äº¤å·®æ¤œè¨¼/Cross Validation](https://ja.wikipedia.org/wiki/%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC)(ä»¥ä¸‹ã€**CV**ã¨å‘¼ã¶)ã¯ã€ãƒ‡ãƒ¼ã‚¿è§£æã®éš›ã«ãƒ¢ãƒ‡ãƒ«ãŒã©ã†ã„ã£ãŸæ¡ä»¶ã®ã¨ãã«è‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‡ºã™ã‹æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ç”¨ã„ã‚‹æ‰‹æ³•ã ã€‚

CVã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä»»æ„ã®æ•°$K$æšã®ã‚°ãƒ«ãƒ¼ãƒ—(æŠ˜ã‚ŠãŸãŸã¿)ã«åˆ†å‰²ã™ã‚‹ã€‚ãã®ä¸­ã®ä¸€ã¤ã‚’ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒƒãƒˆ(validation set)ã¨ã—ãã‚Œä»¥å¤–ã®å…¨ã¦ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã™ã‚‹ã€‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒƒãƒˆã¯åˆ†å‰²ã•ã‚ŒãŸå…¨ã¦ã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒ[ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³æ–¹å¼](https://ja.wikipedia.org/wiki/%E3%83%A9%E3%82%A6%E3%83%B3%E3%83%89%E3%83%AD%E3%83%93%E3%83%B3)(æŒã¡å›ã‚Šåˆ¶)ã§1åº¦ã¥ã¤æ‹…å½“ã—ã¦ã„ãã€‚ã¾ãŸãã®å›ã”ã¨ã«ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒƒãƒˆã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ãŒè¡Œã‚ã‚Œã‚‹ã€‚


## MNISTã®ãƒˆã‚¤ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹
TODO ãƒˆã‚¤ãƒ‡ãƒ¼ã‚¿ã˜ã‚ƒãªãã¦ã¡ã‚ƒã‚“ã¨MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ãˆ
(0)äº‹å‰æº–å‚™(pip installã€MNISTç”»åƒã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰)
(1)ã‚¹ã‚³ã‚¢
(2)confusion matrix=>ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”»åƒã‚’ä½œæˆ
(2)é–“é•ã£ãŸæ•°å­—ã®ç”»åƒã®ã¿ç¢ºèª
(3)æ­£è§£ã¨é–“é•ã£ãŸã‚‚ã®(æ¨ªè»¸ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã€ç¸¦è»¸ãƒ‡ãƒ¼ã‚¿æ•°)ãã‚Œãã‚Œã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆ=>ãã‚Œãã‚Œã®åˆ†å¸ƒã®é•ã„ã‹ã‚‰å¤–ã‚Œå€¤ãŒå½±éŸ¿ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†
â€»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªãƒ³ã‚¯ã‚’è²¼ã‚‹ãã‚‰ã„ã¯ã—ã¦ã„ã„ãŒã•ã‚‰ã«ãã‚Œã‚’è§£èª¬ã™ã‚‹ã®ã¯DRYã«åã™ã‚‹ã€‚
ä¸»å¼µï¼šKNNãŒMNISTã«å¯¾ã—ã¦ã‚¹ã‚³ã‚¢ã©ã®ãã‚‰ã„å‡ºã›ã‚‹ã‹ï¼Ÿã€ã‚ˆã‚Šè‰¯ã„ç²¾åº¦ã‚’é”æˆã§ãã‚‹ã‹ã®ç¤ºå”†ã€‚
=>ã©ã†ã™ã‚Œã°ã«å¯¾ã—ã¦ã€Œãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã›ã°ã„ã„ã€ã¯ä¸€è¦‹å½“ãŸã‚Šå‰ã®è©±ã«æ€ãˆã‚‹ãŒä¸Šè¨˜ã®è€ƒå¯Ÿã«ã‚ˆã£ã¦ãã‚ŒãŒç¢ºã‹ã‚‰ã—ã„ã“ã¨ã«ãªã£ãŸä¸Šã§è¨€ã†ã®ã§ã‚ã‚Œã°ä¾¡å€¤ã¯ã‚ã‚‹ã€‚

# (1)ã‚¹ã‚³ã‚¢
ã‚‚ã—ã‹ã—ã¦splitãŒãƒ©ãƒ³ãƒ€ãƒ ãªã®ã‹ï¼Ÿ

```
import time
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split


def score_by_knn(knn, X_train, y_train, X_test, y_test):
    knn.fit(X_train, y_train)
    score = knn.score(X_test, y_test)
    return score


if __name__ == "__main__":
    time_list = [None] * 7
    start = time.time()  # measurement time
    X, y = fetch_openml("mnist_784", version=1, return_X_y=True, as_frame=False)
    load_time = time.time()  # measurement time
    # np.set_printoptions(threshold=np.inf) # show all of np
    # print("X", X)  # debug
    X_train, X_test, y_train, y_test = train_test_split(
            X, y, train_size=60000, shuffle=False)
    X_not_val, X_val, y_not_val, y_val = train_test_split(
            X_train, y_train, train_size=0.8, shuffle=False)
    print(f"y_train len is {len(y_train)}")  # debug
    print(f"y_val len is {len(y_val)} and y_not_val len is {len(y_not_val)}")  # debug
    print(f"y_test len is {len(y_test)}")  # debug
    print("-" * 15)
    split_time = time.time()  # measurement time
    scores = dict()
    bef_time = time.time()  # measurement time
    para_sel_times = dict()
    for k in range(1, 6):
        knn = KNeighborsClassifier(n_neighbors=k)
        val_score = score_by_knn(knn, X_not_val, y_not_val, X_val, y_val)
        current_time = time.time()
        bef_time, current_time = current_time, current_time - bef_time  # measurement time
        para_sel_times[k] = current_time
        scores[knn] = val_score
        print(f"k is {k}. val_score is {val_score}")
    opt_knn, max_val_score = max(scores.items(), key=lambda x: x[1])  # this knn_model have not learned yet
    print("opt_knn, max_val_score", opt_knn, max_val_score)  # debug
    scoreing_start_time = time.time()
    score = score_by_knn(opt_knn, X_train, y_train, X_test, y_test)
    scoreing_end_time = time.time() - scoreing_start_time
    print(f"score is {score}")  # debug
    # show times
    print("-" * 15)
    print(f"load time is {load_time - start}")
    print(f"split time is {split_time - load_time}")
    for k, t in para_sel_times.items():
        print(f"{k}'s score time is {t}")
    print(f"Test score time is {scoreing_end_time}")
```

ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã¯ä¸‹è¨˜
```
[kumamoto knn_mnist]$ python knn_score.py
y_train len is 60000
y_val len is 12000 and y_not_val len is 48000
y_test len is 10000
---------------
k is 1. val_score is 0.9681666666666666
k is 2. val_score is 0.964
k is 3. val_score is 0.9704166666666667
k is 4. val_score is 0.9700833333333333
k is 5. val_score is 0.9688333333333333
opt_knn, max_val_score KNeighborsClassifier(n_neighbors=3) 0.9704166666666667
score is 0.9705
---------------
load time is 37.099200963974
split time is 0.7950737476348877
1's score time is 36.323387145996094
2's score time is 28.110684871673584
3's score time is 42.3310010433197
4's score time is 47.61889600753784
5's score time is 40.763972997665405
Final score time is 51.22562289237976
```

# (2)confusion matrix=>ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”»åƒã‚’ä½œæˆ


```
import pickle
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import fetch_openml
from matplotlib.colors import LinearSegmentedColormap
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

NEIGHBOR = 5
OPT_KNN = 3  # citing from the result of knn_score.py


color_dict = {
     'red':   [
         (0.0,  1.0, 1.0),
         (0.01,  0.9, 0.9),
         (0.02,  1.0, 1.0),
         (0.5,  1.0, 1.0),
         (1.0,  0.0, 0.0)
         ],

     'green': [
         (0.0,  1.0, 1.0),
         (0.005,  1.0, 1.0),
         (0.015,  0.0, 0.0),
         (1.0,  0.0, 0.0)
         ],

     'blue':  [
         (0.0,  1.0, 1.0),
         (0.005,  1.0, 1.0),
         (0.015,  0.0, 0.0),
         (1.0,  1.0, 1.0)
         ]
     }


if __name__ == "__main__":
    # from sklearn.datasets import load_digits
    # mnist = load_digits() # for small test
    mnist = fetch_openml("mnist_784", version=1, as_frame=False)
    X = mnist.data
    y = mnist.target
    cmap = LinearSegmentedColormap("custom_cmap", color_dict)
    X_train, X_test, y_train, y_test = train_test_split(
            X, y, train_size=60000, shuffle=False)
    knn = KNeighborsClassifier(n_neighbors=OPT_KNN)
    knn.fit(X_train, y_train)
    predicted_y = knn.predict(X_test)
    cfm = confusion_matrix(y_test, predicted_y, labels=knn.classes_, normalize="true")
    print("cfm", cfm)  # debug
    disp = ConfusionMatrixDisplay(confusion_matrix=cfm, display_labels=knn.classes_)
    with open('mydata.pickle', 'wb') as myfile:
        pickle.dump(disp, myfile)
        pickle.dump(knn, myfile)
        pickle.dump(cfm, myfile)
```

pickleã«ä¿å­˜ã—ãŸconfusion matrixã‚’ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¨ã—ã¦è¡¨ç¤ºã™ã‚‹ã€‚

```
import pickle
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap


color_dict = {
     'red':   [
         (0.0,  1.0, 1.0),
         (0.01,  0.9, 0.9),
         (0.02,  1.0, 1.0),
         (0.5,  1.0, 1.0),
         (1.0,  0.0, 0.0)
         ],

     'green': [
         (0.0,  1.0, 1.0),
         (0.005,  1.0, 1.0),
         (0.015,  0.0, 0.0),
         (1.0,  0.0, 0.0)
         ],

     'blue':  [
         (0.0,  1.0, 1.0),
         (0.005,  1.0, 1.0),
         (0.015,  0.0, 0.0),
         (1.0,  1.0, 1.0)
         ]
     }


if __name__ == "__main__":
    with open("mydata.pickle", "rb") as myfile:
        disp = pickle.load(myfile)
        knn = pickle.load(myfile)  # this model have alerady learned train-set
        cfm = pickle.load(myfile)
    cmap = LinearSegmentedColormap("custom_cmap", color_dict)
    _, ax = plt.subplots(figsize=(13, 8))
    """ same process
    fig = plt.figure(figsize=(8, 6))
    ax = fig.subplots()
    """
    disp.plot(cmap=cmap, ax=ax)
    # plt.subplots_adjust(left=0.1, right=0.95, bottom=0.1, top=0.95)  # not working
    plt.show()
```

![](https://storage.googleapis.com/zenn-user-upload/y4eaog6t162p2ve3lmr77j274msp)

# (3)æ­£è§£ã¨é–“é•ã£ãŸã‚‚ã®(æ¨ªè»¸ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã€ç¸¦è»¸ãƒ‡ãƒ¼ã‚¿æ•°)ãã‚Œãã‚Œã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆ=>ãã‚Œãã‚Œã®åˆ†å¸ƒã®é•ã„ã‹ã‚‰å¤–ã‚Œå€¤ãŒå½±éŸ¿ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†

ã¾ãšã¯æ­£è§£ã¨é–“é•ã„ã®ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ

```
import pickle
import numpy as np


def arrage_correct_wrong_list(y_test, predicted_y):
    y_len = len(y_test)
    error_orders = []
    correct_orders = []
    for i in range(y_len):
        if y_test[i] != predicted_y[i]:
            error_orders.append(i)
        else:
            correct_orders.append(i)
    return error_orders, correct_orders


if __name__ == "__main__":
    with open("mydata.pickle", "rb") as myfile:
        disp = pickle.load(myfile)
        knn = pickle.load(myfile)  # this model have alerady learned train-set and takes 3 neighbor
        cfm = pickle.load(myfile)
        X_test = pickle.load(myfile)
        y_test = pickle.load(myfile)
        predicted_y = pickle.load(myfile)

    # np.set_printoptions(threshold=np.inf)  # show all of np
    neigh_dist = knn.kneighbors(X=X_test)[0]
    error_orders, correct_orders = arrage_correct_wrong_list(y_test, predicted_y)
    all_len = len(neigh_dist)
    error_len = len(error_orders)
    all_distances = [0] * all_len
    correct_distances = [0] * (all_len - error_len)
    error_distances = [0] * error_len
    for i, n in enumerate(neigh_dist):
        ave_dist = np.average(n)
        all_distances[i] = ave_dist
    for i, e in enumerate(error_orders):
        error_distances[i] = all_distances[e]
    for i, c in enumerate(correct_orders):
        correct_distances[i] = all_distances[c]

    with open("mydata2.pickle", "wb") as myfile:
        pickle.dump(all_distances, myfile)
        pickle.dump(correct_distances, myfile)
        pickle.dump(error_distances, myfile)
```

ã¤ã¥ã„ã¦ãã®ãƒªã‚¹ãƒˆã‚’åˆ©ç”¨ã—ã¦ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ä½œæˆã™ã‚‹ã€‚

```
import math
import pickle
import numpy as np
import matplotlib.pyplot as plt

if __name__ == "__main__":
    with open("mydata2.pickle", "rb") as myfile:
        all_distances = pickle.load(myfile)
        correct_distances = pickle.load(myfile)
        error_distances = pickle.load(myfile)
    max_b= math.ceil(max(all_distances))
    bins = [i for i in range(0, max_b, 100)]
    fig, axs = plt.subplots(2, 1, sharey=False, figsize=(8, 8))
    axs[0].set_title("Correct distribution")
    axs[1].set_title("Error distribution")
    axs[0].hist(correct_distances, bins=bins, color="blue")
    axs[1].hist(error_distances, bins=bins, color="red")
    plt.show()
```
![](https://storage.googleapis.com/zenn-user-upload/mlvj3fmktijo64xjs7rj79vtvpxp)



### å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

å…ˆã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¡Œã†ã€‚
â€»[Python](https://www.python.org/downloads/)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã§ã‚ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹ã€‚

```
$ pip install scikit-learn \
numpy \
matplotlib
```

```
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_digits
from sklearn.model_selection import cross_val_score

import matplotlib.pyplot as plt
import numpy as np
```

### scikit-learnå†…ã®æ‰‹æ›¸ãã®æ•°å­—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å–å¾—ã—ã€è¡¨ç¤º

```
if __name__ == "__main__":
    digits = load_digits()  # mnist
    # print(digits.data.shape)  (1797, 64)
    
    # 8ç•ªç›®ã®ç”»åƒã‚’è¡¨ç¤º
    plt.gray()
    plt.matshow(digits.images[8])
    plt.show()
    
    # ç”»åƒã®ã‚µã‚¤ã‚º3*3ã«æŒ‡å®šã—ã¦8ç•ªç›®ã®ç”»åƒã‚’è¡¨ç¤º
    plt.figure(1, figsize=(3, 3))
    plt.imshow(digits.images[8], cmap=plt.cm.gray_r, interpolation='nearest')
    plt.show()
```

â€»`digits.data.shape`ã®1797ã¯ãƒ‡ãƒ¼ã‚¿ã®å€‹æ•°ã‚’ã€64ã¯ãƒ”ã‚¯ã‚»ãƒ«ã®å€‹æ•°ã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚

### CVã§ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ãŸä¸Šã§ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã™ã‚‹

```
def cv_experiment_for_knn(k, X, y):
    knn = KNeighborsClassifier(n_neighbors=k)
    score = cross_val_score(knn, X, y, cv=10)
    return score

if __name__ == "__main__":
    X, y = load_digits(return_X_y=True)  # mnist
    # np.set_printoptions(threshold=np.inf) # show all of np
    # print("X", X)  # debug
    scores = dict()
    for k in range(1, 6):
        score = cv_experiment_for_knn(k, X, y)
        scores[k] = score.mean()
    opt_k, max_score = max(scores.items(), key=lambda x:x[1])
    print("opt_k, max_score", opt_k, max_score)  # debug
```



### ã‚ã‚


## ã‚ã‚


# å‚è€ƒæ–‡çŒ®
[matplotlib:Creating a colormap from a list of colors](https://matplotlib.org/stable/gallery/color/custom_cmap.html) 

[Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series) Kevin P. Murphy](https://www.amazon.co.jp/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020)