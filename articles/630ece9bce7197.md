---
title: "KNN„ÅßMNIST„ÇíÂàÜÈ°û(‰ªÆ)"
emoji: "üéÉ"
type: "tech"
topics: []
published: false
---

# Ê¶ÇË¶Å
„Åì„ÅÆË®ò‰∫ã„Åß„ÅØK nearest neighbors(KËøëÂÇçÊ≥ï)„ÇíÁî®„ÅÑ„Å¶MNIST„ÅÆÂàÜÈ°û
* Python„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπÊ©üÊ¢∞Â≠¶Áøí„É©„Ç§„Éñ„É©„É™„ÅÆscikit-learn
‰ªäÂõûÁî®„ÅÑ„Çã„ÅÆ„ÅØscikit-learn„ÅÆ„Éà„Ç§„Éá„Éº„Çø„Çª„ÉÉ„Éà(„É©„Ç§„Éñ„É©„É™„Å´Ê®ôÊ∫ñ„ÅÆÁ∑¥ÁøíÁî®„Éá„Éº„Çø„Çª„ÉÉ„Éà)

# „ÅØ„Åò„ÇÅ„Å´

## ÂâçÊèêÁü•Ë≠ò

### K nearest neighbors
K nearest neighbors(‰ª•‰∏ã„ÄÅKNN„Å®Âëº„Å∂)„ÅØ„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅåÂÖ•Âäõ„Åï„Çå„Åü„Å®„Åç„Å´„Åù„Çå„Å´Ëøë„ÅÑKÂÄã„ÅÆ„Éà„É¨„Éº„Éã„É≥„Ç∞„Éá„Éº„Çø„ÇíÂèñ„Çä„ÄÅ„Åù„Çå„Çâ„ÅÆ„É©„Éô„É´„ÅÆÂ§öÊï∞Ê±∫„ÇíÊé°„Çã„Åì„Å®„Åß„ÄÅ„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅÆ„É©„Éô„É´„Çí‰∫àÊ∏¨„Åô„Çã„É¢„Éá„É´„Åß„ÅÇ„Çã„ÄÇ
Á≠ÜËÄÖ„ÅÆ„Äé[KNN(KËøëÂÇçÊ≥ï)„ÅÆ‰ªïÁµÑ„Åø](https://zenn.dev/kumamoto/articles/bc6230323bc0ad)„Äè„Å´Ë©≥„Åó„ÅÑËß£Ë™¨„Åå„ÅÇ„Çã„ÄÇ

### MNIST
TODO Ë™≠ËÄÖ„ÅåÁü•„Çä„Åü„ÅÑ„ÅÆ„ÅØ„ÄÅMNIST„Åå„Å©„ÅÜ„ÅÑ„ÅÜDS„Åã„Åß„ÅÇ„Å£„Å¶‰Ωú„ÇäÊñπ„Åß„ÅØ„Å™„ÅÑ„ÄÅÁîªÂÉè„ÇÇË≤º„Å£„Å¶„Åä„Åë
[**MNIST**(Modified National 
Institute of Standards)](http://yann.lecun.com/exdb/mnist/)„ÅØ0~9„ÅÆÊâãÊõ∏„ÅçÊï∞Â≠ó„ÅÆÁîªÂÉè„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß60,000Êûö„ÅÆ„Éà„É¨„Éº„Éã„É≥„Ç∞„Éá„Éº„Çø„Å®10,000Êûö„ÅÆ„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÇíÊúâ„Åó„Å¶„ÅÑ„Çã„ÄÇ
![](https://storage.googleapis.com/zenn-user-upload/9oucz58gb5wrizfz0ut1ureprpb4)
>MNIST„ÉÜ„Çπ„Éà„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ„Çµ„É≥„Éó„É´(‰ªÆ)

„Åù„Çå„Åû„Çå„ÅÆ„Éá„Éº„Çø„ÅØÊó¢„Å´(1)28x28„Éî„ÇØ„Çª„É´„ÅÆÁØÑÂõ≤„Å´Âèé„Åæ„Çã„Çà„ÅÜ„Å´„Çµ„Ç§„Ç∫„ÅåÊ≠£Ë¶èÂåñ„Åï„Çå„Å¶„Åä„Çä„ÄÅ(2)„Ç∞„É¨„Éº„Çπ„Ç±„Éº„É´ÁîªÂÉè„Å´„Å™„Çã„Çà„ÅÜ„Ç¢„É≥„ÉÅ„Ç®„Ç§„É™„Ç¢„ÇπÂá¶ÁêÜ„ÇÇË°å„Çè„Çå„Å¶„ÅÑ„Çã„ÄÇ
‚Äª[Ê≠£Ë¶èÂåñ](https://ja.wikipedia.org/wiki/%E6%AD%A3%E8%A6%8F%E5%8C%96#:~:text=%E6%AD%A3%E8%A6%8F%E5%8C%96%EF%BC%88%E3%81%9B%E3%81%84%E3%81%8D%E3%81%8B%E3%80%81%E8%8B%B1%E8%AA%9E,%E3%81%A6%E3%82%82%E5%90%8C%E7%BE%A9%E3%81%A7%E3%81%82%E3%82%8B%E3%80%82)„Å®„ÅØ„Éá„Éº„Çø„Çí‰∏ÄÂÆö„ÅÆ„É´„Éº„É´„Å´Âü∫„Å•„ÅÑ„Å¶Â§âÂΩ¢„ÅóÂà©Áî®„Åó„ÇÑ„Åô„Åè„Åô„Çã„Åì„Å®„ÄÇ


### ‰∫§Â∑ÆÊ§úË®º(Cross Validation)
[‰∫§Â∑ÆÊ§úË®º/Cross Validation](https://ja.wikipedia.org/wiki/%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC)(‰ª•‰∏ã„ÄÅ**CV**„Å®Âëº„Å∂)„ÅØ„ÄÅ„Éá„Éº„ÇøËß£Êûê„ÅÆÈöõ„Å´„É¢„Éá„É´„Åå„Å©„ÅÜ„ÅÑ„Å£„ÅüÊù°‰ª∂„ÅÆ„Å®„Åç„Å´ËâØ„ÅÑ„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÇíÂá∫„Åô„ÅãÊ§úË®º„Åô„Çã„Åü„ÇÅ„Å´Áî®„ÅÑ„ÇãÊâãÊ≥ï„Å†„ÄÇ

CV„ÅØ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí‰ªªÊÑè„ÅÆÊï∞$K$Êûö„ÅÆ„Ç∞„É´„Éº„Éó(Êäò„Çä„Åü„Åü„Åø)„Å´ÂàÜÂâ≤„Åô„Çã„ÄÇ„Åù„ÅÆ‰∏≠„ÅÆ‰∏Ä„Å§„Çí„Éê„É™„Éá„Éº„Ç∑„Éß„É≥„Çª„ÉÉ„Éà(validation set)„Å®„Åó„Åù„Çå‰ª•Â§ñ„ÅÆÂÖ®„Å¶„ÅÆ„Ç∞„É´„Éº„Éó„Çí„Éà„É¨„Éº„Éã„É≥„Ç∞„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å®„Åô„Çã„ÄÇ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥„Çª„ÉÉ„Éà„ÅØÂàÜÂâ≤„Åï„Çå„ÅüÂÖ®„Å¶„ÅÆ„Ç∞„É´„Éº„Éó„Åå[„É©„Ç¶„É≥„Éâ„É≠„Éì„É≥ÊñπÂºè](https://ja.wikipedia.org/wiki/%E3%83%A9%E3%82%A6%E3%83%B3%E3%83%89%E3%83%AD%E3%83%93%E3%83%B3)(ÊåÅ„Å°Âõû„ÇäÂà∂)„Åß1Â∫¶„Å•„Å§ÊãÖÂΩì„Åó„Å¶„ÅÑ„Åè„ÄÇ„Åæ„Åü„Åù„ÅÆÂõû„Åî„Å®„Å´„Éê„É™„Éá„Éº„Ç∑„Éß„É≥„Çª„ÉÉ„Éà„ÇíÁî®„ÅÑ„Åü„É¢„Éá„É´„ÅÆË©ï‰æ°„ÅåË°å„Çè„Çå„Çã„ÄÇ


## MNIST„ÅÆ„Éà„Ç§„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„Å¶ÁîªÂÉè„ÇíË°®Á§∫„Åô„Çã
TODO „Éà„Ç§„Éá„Éº„Çø„Åò„ÇÉ„Å™„Åè„Å¶„Å°„ÇÉ„Çì„Å®MNIST„ÅÆ„Éá„Éº„Çø„Çí‰Ωø„Åà
(0)‰∫ãÂâçÊ∫ñÂÇô(pip install„ÄÅMNISTÁîªÂÉè„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ)
(1)„Çπ„Ç≥„Ç¢
(2)confusion matrix=>„Éí„Éº„Éà„Éû„ÉÉ„ÉóÁîªÂÉè„Çí‰ΩúÊàê
(2)ÈñìÈÅï„Å£„ÅüÊï∞Â≠ó„ÅÆÁîªÂÉè„ÅÆ„ÅøÁ¢∫Ë™ç
(3)Ê≠£Ëß£„Å®ÈñìÈÅï„Å£„Åü„ÇÇ„ÅÆ(Ê®™Ëª∏„É¶„Éº„ÇØ„É™„ÉÉ„ÉâË∑ùÈõ¢„ÄÅÁ∏¶Ëª∏„Éá„Éº„ÇøÊï∞)„Åù„Çå„Åû„Çå„ÅÆ„Éí„Çπ„Éà„Ç∞„É©„É†„Çí‰ΩúÊàê=>„Åù„Çå„Åû„Çå„ÅÆÂàÜÂ∏É„ÅÆÈÅï„ÅÑ„Åã„ÇâÂ§ñ„ÇåÂÄ§„ÅåÂΩ±Èüø„Åó„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„ÇíÁ§∫ÂîÜ
‚Äª„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆ„É™„É≥„ÇØ„ÇíË≤º„Çã„Åè„Çâ„ÅÑ„ÅØ„Åó„Å¶„ÅÑ„ÅÑ„Åå„Åï„Çâ„Å´„Åù„Çå„ÇíËß£Ë™¨„Åô„Çã„ÅÆ„ÅØDRY„Å´Âèç„Åô„Çã„ÄÇ
‰∏ªÂºµÔºöKNN„ÅåMNIST„Å´ÂØæ„Åó„Å¶„Çπ„Ç≥„Ç¢„Å©„ÅÆ„Åè„Çâ„ÅÑÂá∫„Åõ„Çã„ÅãÔºü„ÄÅ„Çà„ÇäËâØ„ÅÑÁ≤æÂ∫¶„ÇíÈÅîÊàê„Åß„Åç„Çã„Åã„ÅÆÁ§∫ÂîÜ„ÄÇ
=>„Å©„ÅÜ„Åô„Çå„Å∞„Å´ÂØæ„Åó„Å¶„Äå„Éá„Éº„ÇøÈáè„ÇíÂ¢ó„ÇÑ„Åõ„Å∞„ÅÑ„ÅÑ„Äç„ÅØ‰∏ÄË¶ãÂΩì„Åü„ÇäÂâç„ÅÆË©±„Å´ÊÄù„Åà„Çã„Åå‰∏äË®ò„ÅÆËÄÉÂØü„Å´„Çà„Å£„Å¶„Åù„Çå„ÅåÁ¢∫„Åã„Çâ„Åó„ÅÑ„Åì„Å®„Å´„Å™„Å£„Åü‰∏ä„ÅßË®Ä„ÅÜ„ÅÆ„Åß„ÅÇ„Çå„Å∞‰æ°ÂÄ§„ÅØ„ÅÇ„Çã„ÄÇ

# (1)„Çπ„Ç≥„Ç¢
„ÇÇ„Åó„Åã„Åó„Å¶split„Åå„É©„É≥„ÉÄ„É†„Å™„ÅÆ„ÅãÔºü

```
import time
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split


def score_by_knn(knn, X_train, y_train, X_test, y_test):
    knn.fit(X_train, y_train)
    score = knn.score(X_test, y_test)
    return score


if __name__ == "__main__":
    time_list = [None] * 7
    start = time.time()  # measurement time
    X, y = fetch_openml("mnist_784", version=1, return_X_y=True, as_frame=False)
    load_time = time.time()  # measurement time
    # np.set_printoptions(threshold=np.inf) # show all of np
    # print("X", X)  # debug
    X_train, X_test, y_train, y_test = train_test_split(
            X, y, train_size=60000, shuffle=False)
    X_not_val, X_val, y_not_val, y_val = train_test_split(
            X_train, y_train, train_size=0.8, shuffle=False)
    print(f"y_train len is {len(y_train)}")  # debug
    print(f"y_val len is {len(y_val)} and y_not_val len is {len(y_not_val)}")  # debug
    print(f"y_test len is {len(y_test)}")  # debug
    print("-" * 15)
    split_time = time.time()  # measurement time
    scores = dict()
    bef_time = time.time()  # measurement time
    para_sel_times = dict()
    for k in range(1, 6):
        knn = KNeighborsClassifier(n_neighbors=k)
        val_score = score_by_knn(knn, X_not_val, y_not_val, X_val, y_val)
        current_time = time.time()
        bef_time, current_time = current_time, current_time - bef_time  # measurement time
        para_sel_times[k] = current_time
        scores[knn] = val_score
        print(f"k is {k}. val_score is {val_score}")
    opt_knn, max_val_score = max(scores.items(), key=lambda x: x[1])  # this knn_model have not learned yet
    print("opt_knn, max_val_score", opt_knn, max_val_score)  # debug
    scoreing_start_time = time.time()
    score = score_by_knn(opt_knn, X_train, y_train, X_test, y_test)
    scoreing_end_time = time.time() - scoreing_start_time
    print(f"score is {score}")  # debug
    # show times
    print("-" * 15)
    print(f"load time is {load_time - start}")
    print(f"split time is {split_time - load_time}")
    for k, t in para_sel_times.items():
        print(f"{k}'s score time is {t}")
    print(f"Test score time is {scoreing_end_time}")
```

„Ç¢„Ç¶„Éà„Éó„ÉÉ„Éà„ÅØ‰∏ãË®ò
```
[kumamoto knn_mnist]$ python knn_score.py
y_train len is 60000
y_val len is 12000 and y_not_val len is 48000
y_test len is 10000
---------------
k is 1. val_score is 0.9681666666666666
k is 2. val_score is 0.964
k is 3. val_score is 0.9704166666666667
k is 4. val_score is 0.9700833333333333
k is 5. val_score is 0.9688333333333333
opt_knn, max_val_score KNeighborsClassifier(n_neighbors=3) 0.9704166666666667
score is 0.9705
---------------
load time is 37.099200963974
split time is 0.7950737476348877
1's score time is 36.323387145996094
2's score time is 28.110684871673584
3's score time is 42.3310010433197
4's score time is 47.61889600753784
5's score time is 40.763972997665405
Final score time is 51.22562289237976
```

# (2)confusion matrix=>„Éí„Éº„Éà„Éû„ÉÉ„ÉóÁîªÂÉè„Çí‰ΩúÊàê


```
import pickle
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import fetch_openml
from matplotlib.colors import LinearSegmentedColormap
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

NEIGHBOR = 5
OPT_KNN = 3  # citing from the result of knn_score.py


color_dict = {
     'red':   [
         (0.0,  1.0, 1.0),
         (0.01,  0.9, 0.9),
         (0.02,  1.0, 1.0),
         (0.5,  1.0, 1.0),
         (1.0,  0.0, 0.0)
         ],

     'green': [
         (0.0,  1.0, 1.0),
         (0.005,  1.0, 1.0),
         (0.015,  0.0, 0.0),
         (1.0,  0.0, 0.0)
         ],

     'blue':  [
         (0.0,  1.0, 1.0),
         (0.005,  1.0, 1.0),
         (0.015,  0.0, 0.0),
         (1.0,  1.0, 1.0)
         ]
     }


if __name__ == "__main__":
    # from sklearn.datasets import load_digits
    # mnist = load_digits() # for small test
    mnist = fetch_openml("mnist_784", version=1, as_frame=False)
    X = mnist.data
    y = mnist.target
    cmap = LinearSegmentedColormap("custom_cmap", color_dict)
    X_train, X_test, y_train, y_test = train_test_split(
            X, y, train_size=60000, shuffle=False)
    knn = KNeighborsClassifier(n_neighbors=OPT_KNN)
    knn.fit(X_train, y_train)
    predicted_y = knn.predict(X_test)
    cfm = confusion_matrix(y_test, predicted_y, labels=knn.classes_, normalize="true")
    print("cfm", cfm)  # debug
    disp = ConfusionMatrixDisplay(confusion_matrix=cfm, display_labels=knn.classes_)
    with open('mydata.pickle', 'wb') as myfile:
        pickle.dump(disp, myfile)
        pickle.dump(knn, myfile)
        pickle.dump(cfm, myfile)
```

pickle„Å´‰øùÂ≠ò„Åó„Åüconfusion matrix„Çí„Éí„Éº„Éà„Éû„ÉÉ„Éó„Å®„Åó„Å¶Ë°®Á§∫„Åô„Çã„ÄÇ

```
import pickle
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap


color_dict = {
     'red':   [
         (0.0,  1.0, 1.0),
         (0.01,  0.9, 0.9),
         (0.02,  1.0, 1.0),
         (0.5,  1.0, 1.0),
         (1.0,  0.0, 0.0)
         ],

     'green': [
         (0.0,  1.0, 1.0),
         (0.005,  1.0, 1.0),
         (0.015,  0.0, 0.0),
         (1.0,  0.0, 0.0)
         ],

     'blue':  [
         (0.0,  1.0, 1.0),
         (0.005,  1.0, 1.0),
         (0.015,  0.0, 0.0),
         (1.0,  1.0, 1.0)
         ]
     }


if __name__ == "__main__":
    with open("mydata.pickle", "rb") as myfile:
        disp = pickle.load(myfile)
        knn = pickle.load(myfile)  # this model have alerady learned train-set
        cfm = pickle.load(myfile)
    cmap = LinearSegmentedColormap("custom_cmap", color_dict)
    _, ax = plt.subplots(figsize=(13, 8))
    """ same process
    fig = plt.figure(figsize=(8, 6))
    ax = fig.subplots()
    """
    disp.plot(cmap=cmap, ax=ax)
    # plt.subplots_adjust(left=0.1, right=0.95, bottom=0.1, top=0.95)  # not working
    plt.show()
```

![](https://storage.googleapis.com/zenn-user-upload/y4eaog6t162p2ve3lmr77j274msp)

# (3)Ê≠£Ëß£„Å®ÈñìÈÅï„Å£„Åü„ÇÇ„ÅÆ(Ê®™Ëª∏„É¶„Éº„ÇØ„É™„ÉÉ„ÉâË∑ùÈõ¢„ÄÅÁ∏¶Ëª∏„Éá„Éº„ÇøÊï∞)„Åù„Çå„Åû„Çå„ÅÆ„Éí„Çπ„Éà„Ç∞„É©„É†„Çí‰ΩúÊàê=>„Åù„Çå„Åû„Çå„ÅÆÂàÜÂ∏É„ÅÆÈÅï„ÅÑ„Åã„ÇâÂ§ñ„ÇåÂÄ§„ÅåÂΩ±Èüø„Åó„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„ÇíÁ§∫ÂîÜ

„Åæ„Åö„ÅØÊ≠£Ëß£„Å®ÈñìÈÅï„ÅÑ„ÅÆ„É¶„Éº„ÇØ„É™„ÉÉ„ÉâË∑ùÈõ¢„ÅÆ„É™„Çπ„Éà„Çí‰ΩúÊàê

```
import pickle
import numpy as np


def arrage_correct_wrong_list(y_test, predicted_y):
    y_len = len(y_test)
    error_orders = []
    correct_orders = []
    for i in range(y_len):
        if y_test[i] != predicted_y[i]:
            error_orders.append(i)
        else:
            correct_orders.append(i)
    return error_orders, correct_orders


if __name__ == "__main__":
    with open("mydata.pickle", "rb") as myfile:
        disp = pickle.load(myfile)
        knn = pickle.load(myfile)  # this model have alerady learned train-set and takes 3 neighbor
        cfm = pickle.load(myfile)
        X_test = pickle.load(myfile)
        y_test = pickle.load(myfile)
        predicted_y = pickle.load(myfile)

    # np.set_printoptions(threshold=np.inf)  # show all of np
    neigh_dist = knn.kneighbors(X=X_test)[0]
    error_orders, correct_orders = arrage_correct_wrong_list(y_test, predicted_y)
    all_len = len(neigh_dist)
    error_len = len(error_orders)
    all_distances = [0] * all_len
    correct_distances = [0] * (all_len - error_len)
    error_distances = [0] * error_len
    for i, n in enumerate(neigh_dist):
        ave_dist = np.average(n)
        all_distances[i] = ave_dist
    for i, e in enumerate(error_orders):
        error_distances[i] = all_distances[e]
    for i, c in enumerate(correct_orders):
        correct_distances[i] = all_distances[c]

    with open("mydata2.pickle", "wb") as myfile:
        pickle.dump(all_distances, myfile)
        pickle.dump(correct_distances, myfile)
        pickle.dump(error_distances, myfile)
```

„Å§„Å•„ÅÑ„Å¶„Åù„ÅÆ„É™„Çπ„Éà„ÇíÂà©Áî®„Åó„Å¶„Éí„Çπ„Éà„Ç∞„É©„É†„Çí‰ΩúÊàê„Åô„Çã„ÄÇ

```
import math
import pickle
import numpy as np
import matplotlib.pyplot as plt

if __name__ == "__main__":
    with open("mydata2.pickle", "rb") as myfile:
        all_distances = pickle.load(myfile)
        correct_distances = pickle.load(myfile)
        error_distances = pickle.load(myfile)
    max_b= math.ceil(max(all_distances))
    bins = [i for i in range(0, max_b, 100)]
    fig, axs = plt.subplots(2, 1, sharey=False, figsize=(8, 8))
    axs[0].set_title("Correct distribution")
    axs[1].set_title("Error distribution")
    axs[0].hist(correct_distances, bins=bins, color="blue")
    axs[1].hist(error_distances, bins=bins, color="red")
    plt.show()
```
![](https://storage.googleapis.com/zenn-user-upload/mlvj3fmktijo64xjs7rj79vtvpxp)



### ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„ÇÑ„É¢„Ç∏„É•„Éº„É´„Çí„Ç§„É≥„Éù„Éº„Éà

ÂÖà„Å´ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„ÇÑ„É¢„Ç∏„É•„Éº„É´„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´„ÄÅ„Ç§„É≥„Éù„Éº„Éà„ÇíË°å„ÅÜ„ÄÇ
‚Äª[Python](https://www.python.org/downloads/)„Åå„Ç§„É≥„Çπ„Éà„Éº„É´Ê∏à„Åø„Åß„ÅÇ„Çã„Åì„Å®„ÇíÂâçÊèê„Å®„Åô„Çã„ÄÇ

```
$ pip install scikit-learn \
numpy \
matplotlib
```

```
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_digits
from sklearn.model_selection import cross_val_score

import matplotlib.pyplot as plt
import numpy as np
```

### scikit-learnÂÜÖ„ÅÆÊâãÊõ∏„Åç„ÅÆÊï∞Â≠ó„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÂèñÂæó„Åó„ÄÅË°®Á§∫

```
if __name__ == "__main__":
    digits = load_digits()  # mnist
    # print(digits.data.shape)  (1797, 64)
    
    # 8Áï™ÁõÆ„ÅÆÁîªÂÉè„ÇíË°®Á§∫
    plt.gray()
    plt.matshow(digits.images[8])
    plt.show()
    
    # ÁîªÂÉè„ÅÆ„Çµ„Ç§„Ç∫3*3„Å´ÊåáÂÆö„Åó„Å¶8Áï™ÁõÆ„ÅÆÁîªÂÉè„ÇíË°®Á§∫
    plt.figure(1, figsize=(3, 3))
    plt.imshow(digits.images[8], cmap=plt.cm.gray_r, interpolation='nearest')
    plt.show()
```

‚Äª`digits.data.shape`„ÅÆ1797„ÅØ„Éá„Éº„Çø„ÅÆÂÄãÊï∞„Çí„ÄÅ64„ÅØ„Éî„ÇØ„Çª„É´„ÅÆÂÄãÊï∞„ÇíË°®„Åó„Å¶„ÅÑ„Çã„ÄÇ

### CV„Åß„É¢„Éá„É´„ÇíÈÅ∏Êäû„Åó„Åü‰∏ä„Åß„Çπ„Ç≥„Ç¢„ÇíÁÆóÂá∫„Åô„Çã

```
def cv_experiment_for_knn(k, X, y):
    knn = KNeighborsClassifier(n_neighbors=k)
    score = cross_val_score(knn, X, y, cv=10)
    return score

if __name__ == "__main__":
    X, y = load_digits(return_X_y=True)  # mnist
    # np.set_printoptions(threshold=np.inf) # show all of np
    # print("X", X)  # debug
    scores = dict()
    for k in range(1, 6):
        score = cv_experiment_for_knn(k, X, y)
        scores[k] = score.mean()
    opt_k, max_score = max(scores.items(), key=lambda x:x[1])
    print("opt_k, max_score", opt_k, max_score)  # debug
```



### „ÅÇ„ÅÇ


## „ÅÇ„ÅÇ


# ÂèÇËÄÉÊñáÁåÆ
[matplotlib:Creating a colormap from a list of colors](https://matplotlib.org/stable/gallery/color/custom_cmap.html) 

[Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series) Kevin P. Murphy](https://www.amazon.co.jp/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020)