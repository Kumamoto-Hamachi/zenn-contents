{
  "title": "MurphyのMachine Learningをしっかり読んでいく。",
  "closed": false,
  "archived": false,
  "created_at": "2021-03-20",
  "comments": [
    {
      "author": "kumamoto",
      "created_at": "2021-03-20",
      "body_markdown": "# [MurphyのMachine Learning](https://www.amazon.co.jp/dp/B08FZLD4J4/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1)\n\n# 英文メモ\n# 0.Preface\nP.28\nPrior exposure to statistics is helpful but not necessary.\ninferential推論\nelicit引き出す\n- probabilistic approach\nThe systematic application of probabilistic reasoning to all inferential problems, including inferring parameters of statistical models=Bayesian approachの価値中立な言い方\n- maximum likelihood estimation\n最尤推定、ベイズ法とは違うが確率論的なパラダイムに属する\n- heuristic methods\nある程度正解に近い解を見つけ出すための経験則や発見方法。本書ではモデルベース的なアプローチを基本的に採る。\n- モデルとアルゴリズムは違う\nあるモデルに対しては、様々なアルゴリズムを適用することができます。逆に言えば、どのようなアルゴリズムであっても、様々なモデルに適用できることが多い。this kind of modularityのおかげで分割して捉えられる。\n- language of graphical models\n数式のこと。グラフというのは辺と点があるデータ構造のこと。\n- Octave/PMTK\nOcataveはフリーバージョンのmatlab。数値解析とデータビジュアライゼーションのためのソフト。\nPMTKはMATLABソフトウェアのパッケージ。\n\n# 1.Introduction\n### Machine learning: what and why?\n世の中に流通しているデータ量は増加の一途をたどっており、それを自動的に分析する手法が求められている。それを提供するのがMachine Learningだ！\nジョン・ネイスビッツ「我々は情報に溺れながら、知識に飢えている」\ndeluge洪水\nWe will describe a wide variety of probabilistic models, suitable for a wide variety of data and tasks. We will also describe a wide variety of algorithms for learning and using such models.\nad hoc(その場しのぎ)なやり方は説明しない。\n- long tail\n少数の者がcommon(general)で多くのものが非常にrareであること。あらゆるドメインで見られがちな特性で大規模なデータセットであっても有効なデータの数はかなり小さなものになるという話で出てくる。\n=>\n- Two main types in ML\n\n- Predictive or Supervised Learning\n予測学習？と教師あり学習\n![](https://storage.googleapis.com/zenn-user-upload/y1jdrhq0iqrfyo1zbyde9g1wde76)\n目標は、入力-出力ペアのラベル付きの(データ)セットDが与えられたときに、入力xから出力yへのマッピング(写像)を学習することです。\nDはトレーニングセットとも呼ばれ、Nはサンプル数を表します。\n※ちなみにxが太字になっているのはベクトルであることを表している。ここで言うベクトルとは統計学で言うところの項目のようなもの。(出力または応答変数の形式は原則的に何でもよいのですが、ほとんどの手法では)yiがある有限集合からのカテゴリー変数または名目変数/名義変数(nominal variable)であると仮定しています。\n\n- 名義変数(nominal variable)\n他と区別し分類するための名称のようなもの(男女、血液型、郵便番号など)\n\n- 特徴量、属性、共変量[covariate](http://jspt.japanpt.or.jp/ebpt_glossary/covariate.html#:~:text=%E5%88%86%E6%95%A3%E5%88%86%E6%9E%90%E3%82%92%E8%A1%8C%E3%81%86%E3%81%A8%E3%81%8D,%E8%A6%81%E5%9B%A0%E3%81%A8%E5%91%BC%E3%81%B0%E3%82%8C%E3%81%BE%E3%81%99%EF%BC%8E)\n共変量は分散分析を行うときに解析に含めるデータのうち，連続量で量的に表される変数のことをいいます．結果と“共”に変わる原因と思われる“変量”というわけです．回帰分析で呼ぶところの説明変数（独立変数）と同等です．これに対して，質的に表される変数は要因と呼ばれます．\n\n",
      "body_updated_at": "2021-03-20"
    },
    {
      "author": "kumamoto",
      "created_at": "2021-03-20",
      "body_markdown": "# 序文(Preface)\n## イントロ\n機械学習のゴールは自動的にデータの中のパターンを特定/検出(detect)することが出来るようし、発見したパターンから未来のデータやその他の興味深いアウトプットを予測することです。\n機械学習は統計学やデータマイニングに関連するが強調点や技術用語に違いがある。\nこの本では、分子生物学/テキスト処理/コンピューターグラフィックス/ロボティクスを題材に分野の細やかな紹介をしていく。\n## 前提知識\n基礎的なmultivariate caluculus、probability、liner algebra、プログラミングの知識を前提とする。(多変数解析学[偏微分]、確率、線形代数)\n\n# Introduction\n\n## 1.1 Machine learning what and why?\n\n"
    }
  ]
}